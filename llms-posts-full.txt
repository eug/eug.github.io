---
title: An Obvious Guide on Prompting
subtitle: Because apparently, this needed to be said.
tags: [critical-thinking, prompting, discipline, ai]
created_at: 2025-06-08
---

Large Language Models (LLMs) are powerful, but their value depends on how you use them. It's easy to treat them like oracles or fall into the convenience trap, which is a waste of their potential and your brainpower. This is not a guide about prompting tricks or clever techniques — it's about how to think *with* AI, not just get answers *from* it.

This guide is for the everyday users: professionals, students, and curious minds who turn to LLMs to solve daily problems, get unstuck on projects, or explore new ideas. This is for those who haven't yet considered what happens when convenience becomes dependence.

>I once thought this guide would be redundant — that its advice was obvious. But observing how many people misuse these tools, it's become clear that's not the case. This is my attempt to state these principles plainly, because the real skill isn't in crafting the perfect prompt, but in maintaining intentional, critical thinking throughout the process.

### The Illusion of the Oracle

It's easy to see an LLM as a digital oracle. We ask, and it answers with confidence and eloquence. This conversational interface is a triumph of design, but it can also be misleading. Underneath the smooth surface is a system that works in a fundamentally non-human way.

The most well-known quirk is "[hallucination](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence))", where the model generates plausible but false information. An LLM doesn't "know" facts; it generates statistically likely text. This means it can invent sources or misstate details with complete confidence, making blind trust a risky strategy.

Foundational model companies like [OpenAI](https://model-spec.openai.com/2025-04-11.html), [Anthropic](https://www-cdn.anthropic.com/6be99a52cb68eb70eb9572b4cafad13df32ed995.pdf), and [Google](https://modelcards.withgoogle.com/model-cards) have published specifications that reveal the guardrails and design principles shaping model behavior. While a step towards transparency, these documents are dense and technical. More illuminating are deep dives into how these models "think". An excellent [Anthropic article](https://transformer-circuits.pub/2025/attribution-graphs/biology.html) demystifies this, showing that what looks like "reasoning" is often a form of sophisticated pattern-matching. It's a powerful tool for generating text, but it's not a conscious thinker. Understanding this distinction is the first step toward using it effectively.

### The Convenience Trap

Our brains are [wired to take the path of least resistance](https://www.sciencedirect.com/science/article/abs/pii/S0028393218303981?via%3Dihub); it's an efficient evolutionary trait. AI systems, designed for ease of use, tap directly into this. The smoother the experience, the more we rely on it, which can create a subtle feedback loop.

Consider a software developer who, instead of wrestling with algorithmic complexity, asks an LLM to "write a function to process this data". The model provides a working solution instantly. The immediate problem is solved, but the developer has bypassed an opportunity to deepen their understanding of data structures, performance trade-offs, and edge cases. Consider a marketing professional who asks the AI to "write a blog post about our new product" and publishes the first output verbatim. They have saved time, but have they produced the most compelling, nuanced, or strategically aligned content?

In both cases, the immediate goal is met, but a learning opportunity is missed. This is the core risk of convenience. Over-relying on AI for [core skills can cause them to fade over time](https://addyo.substack.com/p/avoiding-skill-atrophy-in-the-age), turning the tool into a ["velvet cage" that domesticates our intellect](https://francoisxaviermorgand.substack.com/p/what-if-ai-is-making-us-softer-than) through constant validation. It's not that using AI is inherently bad, but that using it *uncritically* makes our own thinking optional. The key is to use it as a tool that assists our thinking, not one that replaces it.

### Don't Outsource Your Brain

Beyond professional skills, how we interact with AI can influence our own thinking habits and resilience. Relying too heavily on a frictionless, validating partner can subtly change how we approach challenges.

Real problem-solving is messy. AI often smooths over the frustrating parts. Relying on this can **make us less willing to do the hard work of thinking**. Researchers warn that this might [affect our cognitive skills](https://www.nature.com/articles/s41562-024-01859-y).

It's also about **intellectual independence**. As highlighted in a recent study on adolescents, while AI dependence may not directly cause mental health problems, individuals with pre-existing issues like anxiety or depression are more likely to use AI as a coping mechanism, leading to [dependence](https://pmc.ncbi.nlm.nih.gov/articles/PMC10944174/). It's easy for the tool to become a crutch, eroding confidence in our own ability to think, write, or create without its assistance.

Finally, you risk creating an **echo chamber** and degrading your social skills. Psychologists have noted that AI can amplify confirmation bias, creating cognitive echo chambers on an [unprecedented scale](https://www.psychologytoday.com/us/blog/harnessing-hybrid-intelligence/202506/the-psychology-of-ais-impact-on-human-cognition). When our worldview is perpetually reinforced, our ability to empathize with different perspectives withers. At the same time, research on users of an AI companion suggests that while such tools can reduce loneliness, an over-reliance can harm real-world interpersonal skills. The AI relationship is inherently one-sided and doesn't require the [reciprocal emotional engagement](https://www.psychologytoday.com/intl/blog/urban-survival/202410/spending-too-much-time-with-ai-could-worsen-social-skills) that builds and maintains human connection.

Keep in the driver's seat. Use these systems consciously, and trade short-term ease for long-term growth and resilience.

### Strategic Prompting: Staying in Control of the Thinking Process

So, how do you get better? Treat AI like a thinking partner, not an answer machine. Here's a simple framework to get you started. It will get you better results and keep your brain from turning to mush.

**1. Decomposition:** Break down a complex request into a series of smaller, logical steps. Instead of "build me a website", a skilled prompter would start with "Outline a sitemap for a personal portfolio website for a software engineer. Include sections for a bio, projects, blog, and contact".

**2. Context Scaffolding:** Provide the necessary context, constraints, and persona for the model. Don't just ask for a summary; specify the audience and purpose.

*   **Weak Prompt:** "Summarize this scientific paper".
*   **Strong Prompt:** "You are a science journalist. Summarize this paper for a technically literate but non-specialist audience. Focus on the core hypothesis, key findings, and their potential real-world implications. Explain the methodology in simple terms. The summary should be no more than 300 words".

**3. Iterative Refinement:** Treat the AI's first response as a starting point, not a final product. Use follow-up prompts to challenge, refine, and deepen the output.

*   **Follow-up:** "That's a good start. Now, expand on the 'potential real-world implications.' What specific industries could this research impact? Are there any ethical considerations the paper overlooks?"

**4. Critical Evaluation:** This is the most crucial step. Always question the output. Is it accurate? Is it biased? Does it make logical sense? A [recent study](https://dl.acm.org/doi/pdf/10.1145/3701716.3715504) highlighted the dominant psychological traits embedded in these models. Understanding these inherent biases is key to knowing where to apply skepticism. Cross-reference claims with reliable sources. Use the LLM to generate ideas, but use your own intellect to validate and synthesize them.

**5. [Know What You Don't Know](https://en.wikipedia.org/wiki/I_know_that_I_know_nothing):** The most important skill is knowing the limits of your own knowledge. How you use an LLM should change depending on how much you know about a topic.

*   **When you are a novice:** On a subject you know little about, an LLM is an extraordinary tool for building a foundational understanding. It can explain complex topics, summarize new fields, and provide a scaffold for learning. Here, the skill is to acknowledge your ignorance and use the AI as a starting point, with the explicit understanding that you must verify this new knowledge against authoritative sources.
*   **When you are an expert:** In your own domain, the AI's role shifts from a teacher to a somewhat unreliable intern. It can accelerate your work by generating boilerplate, brainstorming ideas, or summarizing adjacent information. However, it can also introduce subtle, critical errors that only an expert can detect. Here, the skill is to never fully trust the output. You must critically evaluate its work through the lens of your own deep knowledge, catching flaws and refining its output to meet your high standards.

Knowing what you don't know is the key. It lets you switch between being a student and a master, so you're always in control.

### It's a Tool, Not a Replacement

Using AI well isn't about learning secret tricks. It's about being intentional. Be clear in your questions, use the AI to explore ideas, and always, *always* question the output. It's a tool to help you think, not a replacement for thinking.

The future is not about humans *versus* AI, but humans *with* AI. The nature of that partnership, however, is up to you. You can be a passive consumer, letting your own critical skills take a backseat to the convenience of automated answers. Or you can be active, discerning collaborators, using these tools to push your own thinking further. This second path requires effort and intention, but it's how you transform prompting from a simple query into a core skill for the future. The choice is yours to make with every query you type.

### The Obvious Conclusion

This isn't a threat, it's an opportunity. This technology, for all its imperfections and seductive ease, offers a chance 
to become more intentional about how we think. It's not just about getting better answers from a machine — it's about asking better questions and thinking critically. That kind of thinking is a muscle. It requires training, and while it can be hard, it's worth it to ensure the most important thinking is still your own.

___
---
title: llmstxt for blogs
subtitle: Extending `llms.txt` for Blogs – Give Your LLM an All-Access Pass
tags: [llmtxt, blog]
created_at: 2025-06-02
---

The `llms.txt` proposal ([llmstxt.org](https://llmstxt.org/index.md)) presents a fascinating idea for providing LLM-friendly content, primarily showcased with documentation for projects like FastHTML. It offers a structured avenue for models to access concise, expert-level information.

But what if we explored taking this concept a step further? Could this approach, initially designed for docs, be adapted and extended for the rich, diverse content found on blogs?

## Exploring the Idea: `llms.txt` for Bloggers

Imagine a scenario where your blog isn't just human-readable, but also intentionally LLM-optimized. By potentially extending the `llms.txt` concept, we could explore creating a manifest that points LLMs to the full text of our posts, curated bookmarks, and other relevant metadata.

I've started experimenting with this concept on my own blog. Here's what my site currently generates:

*   A main [llms.txt](https://eug.github.io/llms.txt) with blog metadata, about section, and pointers.
*   [llms-posts-full.txt](https://eug.github.io/llms-posts-full.txt): All blog posts in raw Markdown, concatenated.
*   [llms-bookmarks-full.txt](https://eug.github.io/llms-bookmarks-full.txt): All shared bookmarks in Markdown.

This early experiment aims to provide a richer, structured dataset for LLMs to potentially work with, right from the source.

## A Key Consideration: Licensing and Data Use

Before diving into potential use cases, it feels crucial to consider the digital handshake we might be making when publishing an `llms.txt` file for our blogs. If we provide this structured, LLM-friendly access to our content, are we, in essence, signaling an intent? It seems plausible that this could be interpreted as granting permission for the data to be used in ways that LLMs excel at – which might include, but isn't necessarily limited to:

*   **Training and Fine-tuning:** Could your content become part of the vast datasets used to train future models or fine-tune existing ones on specific styles or topics (like your blog's niche)?
*   **Remixing and Derivative Works:** Might LLMs use your content as a basis for generating new text, summaries, or even entirely new creative works derived from or inspired by your posts?
*   **Indexing and Analysis:** Beyond simple search, could your content be deeply indexed, analyzed for patterns, and cross-referenced in new ways?

This isn't about suggesting a renounce of copyright wholesale, but rather acknowledging that the act of making blog content explicitly available and optimized for machine consumption could carry an implicit consent for these kinds of transformative uses. Is it a *quid pro quo*: we give models better data, and in return, those models can do more interesting things with it, potentially amplifying our blog's reach and impact in new ways? If one isn't comfortable with their content being used this way, then perhaps providing an `llms.txt` wouldn't be the right step.

For those of us who see this as an exciting frontier to explore, it could be a way to actively participate in how AI understands and interacts with the wealth of knowledge and creativity shared on personal blogs.

## From SEO to AEO with `llms.txt`?

The digital landscape appears to be in a period of significant flux. For years, Search Engine Optimization (SEO) was a central focus, emphasizing keywords and rankings to gain visibility on Search Engine Results Pages (SERPs). However, as highlighted by emerging concepts like Answer Engine Optimization (AEO) (see [SurferSEO's article on AEO](https://surferseo.com/blog/answer-engine-optimization/)), the game seems to be evolving. Users, increasingly interacting with AI assistants and sophisticated search tools, now often expect direct answers and conversational results, not just a list of links.

Answer Engines, powered by advanced AI and Natural Language Processing, aim to understand user *intent* and provide precise, concise answers. This is where the idea of `llms.txt` for blogs could become particularly relevant.

*   **Direct Value Delivery:** AEO emphasizes providing answers upfront. An `llms.txt` file, by its very structure, offers a way to give LLMs a direct, no-nonsense summary and pathway to a blog's core content. It's like handing the answer engine the keys to your knowledge base.
*   **Structured for Understanding:** AEO thrives on well-structured content. Schema markup and clear formatting help answer engines interpret and display information effectively. The proposed `llms.txt` format, with its defined sections and Markdown structure, provides a similar level of clarity specifically tailored for LLM consumption.
*   **Aligning with Modern Search Behaviors:** Users are asking questions in natural language, often through voice search or AI chatbots, for which traditional SEO isn't always optimized. An `llms.txt` can help bridge this gap by making a blog's content more readily digestible and understandable for the AI systems that power these new interfaces.
*   **Building Authority in an Age of Answers:** AEO is about establishing content as an authoritative source that provides clear, direct answers. By curating what an LLM sees first through `llms.txt`, bloggers can better position their expertise and ensure their core messages are more easily found and understood by these new information gatekeepers.

In essence, exploring the adoption of `llms.txt` for blogs might not just be about feeding data to a model; it could be a strategic move to align with the principles of AEO. It's potentially about future-proofing content and ensuring it remains visible and valuable as search paradigms evolve from keyword matching to intent fulfillment and direct answer provisioning.

## Potential Use Cases for an LLM-Optimized Blog:

What could an LLM-optimized blog unlock? Here are a few possibilities:

1.  **Smarter Q&A:**
    *   Could users (or the LLM itself) ask complex questions spanning multiple posts? E.g., "What are the common themes in posts tagged 'AI' from the last year?"
    *   Might we get answers based *only* on the blog's content, potentially reducing hallucinations?

2.  **Content Generation & Augmentation Ideas:**
    *   Could it help draft a new blog post in the style of a 'Python Tips' series, focusing on asynchronous programming?
    *   Might it suggest alternative titles for a draft post?
    *   Could it generate a summary of a 'Project X Retrospective' series?

3.  **Enhanced Search & Discovery Possibilities:**
    *   Could one perform semantic searches across all articles and even curated bookmarks? E.g., "Find articles discussing 'serverless architectures' and any related bookmarks saved."
    *   Could an LLM assist in auto-tagging posts or suggesting related articles with much higher accuracy?

4.  **Personalized Experiences (Further Down the Line?):**
    *   Imagine an LLM-powered agent that has processed an entire blog. Could it offer personalized summaries or learning paths based on a user's query and the blog's content?

5.  **Data Portability & Analysis Opportunities:**
    *   Could one more easily feed an entire body of work into different LLM tools or local models for analysis, without complex scraping?

Ultimately, these are just a few initial thoughts. The core idea is that by making our blog content more accessible and understandable to LLMs, we could unlock entirely new ways for readers (and ourselves) to interact with, synthesize, and draw connections across our accumulated knowledge. Imagine an experience where insights from multiple related posts are seamlessly integrated together in response to a query, creating a much richer and more dynamic form of content consumption than simply reading individual articles in isolation. The potential to transform blog reading into a more interactive, interconnected journey seems quite exciting.

## A Practical Dive: Unlocking Bookmark Insights with NotebookLM

I've been experimenting with ways to make my bookmarks more accessible to the general public, moving away from private silos – a journey I detailed in my post "[My bookmarks are public now](my-bookmarks-are-public-now.html)". Part of this exploration involves not just making them public, but also easier to query and gain insights from, even in their raw, unstructured form. We all have bookmarks, right? Traditionally, making them useful meant meticulous tagging, and revisiting them. But what if we could just... not, or at least, less so?

I've been playing around with feeding my blog's [llms-bookmarks-full.txt](https://eug.github.io/llms-bookmarks-full.txt) into tools like Google's NotebookLM.

The experience is quite revealing. For example, one could ask a general question like *"Can you list some articles about software engineering best practices?"* and the system can pull relevant links directly from that raw, unstructured list of bookmarks. Suddenly, there's potential to get insights and answers from saved links *without any upfront organization* – a task that used to consume considerable time. It's like having a research assistant that's already processed everything bookmarked. This could dramatically lower the barrier to actually *using* our digital breadcrumbs. 

<img src="../static/imgs/20250602_1.png" width="800" alt="Bookmark general insights by NotebookLM">

Going a step further, as shown in the second image, one might even explore more abstract queries. For instance, posing a question like, *"What can you say about the personality of this person based on their bookmarks?"* yielded a response that was, it's worth noting, quite accurate given the nature of the saved links. This hints at the potential for LLMs to draw higher-level inferences from curated data, moving beyond simple information retrieval into areas that feel more akin to understanding an individual's interests and perhaps even their thought patterns, all derived from their digital trail.

<img src="../static/imgs/20250602_2.png" width="800" alt="Bookmark personal insights by NotebookLM">

If you're curious to try it yourself, you can chat directly with my bookmarks by visiting [Google NotebookLM](https://notebooklm.google.com/notebook/65911a6f-ce1b-4604-bb7d-178aa88f67ea?original_referer=https%3A%2F%2Fwww.google.com%23&pli=1).

## Wrap up

So, what if we started thinking more intentionally about how our blogs feed into these rapidly evolving language models? The experiment with NotebookLM, simply by pointing it at a raw list of bookmarks, offers a small taste of the potential. Imagine the richer interactions and deeper insights we could unlock if we consciously provided LLMs with access to our full posts and curated links in a more structured, yet still easily manageable way.

Whether or not foundational model companies decide to prioritize direct ingestion of such `llms.txt` files (or similar conventions) remains to be seen. However, the value for individual creators and their audiences in making content more AI-accessible might be a compelling enough reason to explore these paths. It empowers us to leverage a growing ecosystem of AI tools with our own curated knowledge bases, on our own terms.

This isn't about a rigid specification, but rather an open invitation to explore. How might we, content creators, make our digital footprints more readily useful for these new forms of AI-driven discovery and synthesis? What other simple experiments could we run? What are your thoughts on extending concepts like `llms.txt` to the world of blogging, or other creative approaches to bridge our content with AI?

___
---
title: Vibe-code your own SSG
subtitle: Stop wrestling with frameworks. Vibe code your own lean static site generator.
tags: [vibe-code, ssg, python, minimalist, DIY]
created_at: 2025-06-01
---

So you want a simple blog. Just a place to jot down your experiments, share some thoughts. Static HTML is the obvious, robust choice. But writing raw HTML like it's 1999? Nah. You want Markdown, maybe a sprinkle of templating, a way to manage posts without pulling your hair out.

The usual suspects – [Jekyll](https://jekyllrb.com/), [Astro](https://astro.build/), [Hugo](https://gohugo.io/) – they're powerful, sure. But they can also feel like bringing a bazooka to a knife fight. Dependencies, complex configurations, a whole ecosystem to learn. What if you just want to get your words out there, with minimal fuss?

I hit this point recently and decided to "vibe-code" my own Static Site Generator (SSG). Turns out, it's surprisingly straightforward and a great way to understand what these tools actually *do*. Forget the bloat; let's vibe-code something lean.

## Here's the bare-bones recipe

**0. Programming Language: Your Choice**

Honestly, pick your poison. Python, Node.js, Ruby, even a shell script if you're feeling particularly masochistic. The core logic is simple enough for any modern language. I went with Python because its standard library is packed with goodies for file manipulation, and excellent libraries for Markdown and templating (like `Markdown` and `Jinja2`) are a `pip install` away. The key is picking something you're comfortable with and that won't get in your way.

**1. The Generation Script: Your SSG's Heart**

This is where the magic happens. At its core, your script will:

* **Scan for content:** Find all your Markdown files (your blog posts).
* **Parse metadata:** Extract frontmatter (title, date, tags, etc.) from each post. YAML or JSON are common choices here. Most Markdown libraries can handle this.
* **Convert Markdown to HTML:** Transform your post content into web-friendly HTML.
* **Apply templates:** Inject the generated HTML and metadata into your base HTML templates (e.g., one for a single post, one for the homepage).
* **Write output:** Save the final HTML files to a designated output directory (often `dist` or `public`).

Keep it simple. You don't need a complex plugin architecture for version 0.1. Focus on the core transformation pipeline.

**2. Templates Folder: The Skeleton of Your Site**

These are your HTML blueprints. You'll likely want at least:

* `base.html`: The main site structure (header, footer, navigation). Other templates will extend this.
* `post.html`: How a single blog post is displayed.
* `index.html` (or `home.html`): Your homepage, probably listing recent posts.

Templating engines like Jinja2 (Python), Handlebars (JavaScript), or Liquid (Ruby, and what Jekyll uses) are your friends here. They let you use variables, loops, and includes to keep your HTML DRY (Don't Repeat Yourself).

Example `post.html` (Jinja2-ish):
```html
{% extends "base.html" %}
{% block title %}{{ post.title }}{% endblock %}
{% block content %}
  <h1>{{ post.title }}</h1>
  <p class="date">Published on: {{ post.date }}</p>
  <div class="post-content">
    {{ post.content_html | safe }}
  </div>
{% endblock %}
```

**3. Assets Folder: The Style and Flair**

This is where your CSS, JavaScript (if any), images, and fonts reside. Your generation script will likely just copy these files directly into the output directory, maintaining their structure.
Start with a single `style.css`. You can always add more later. Resist the urge to install a massive CSS framework unless you *really* need it. A few well-crafted CSS rules can go a long way.

**4. Posts Folder: Your Content Hub**

A straightforward directory where each `.md` file is a blog post. A common convention is to name files like `YYYY-MM-DD-your-post-slug.md`. The frontmatter at the top of each file is key for your generation script.

Example post (`2025-06-01-my-first-post.md`):
```markdown
---
title: "My First Awesome Post"
date: 2025-06-01
tags: [introduction, exciting-stuff]
---

Hello world! This is my first post, generated by **my own** SSG.
It feels good.
```

**5. The "Extra Support" Goodies: Because Details Matter**

Once you have the basics, these aren't hard to add and make your site a better web citizen:

*   `atom.xml` / `rss.xml`: An XML feed for aggregators. Your script can generate this by looping through your posts.
*   `robots.txt`: Tells search engine crawlers what they can and cannot index.
*   `sitemap.xml`: Helps search engines discover all the pages on your site.
*   `CNAME` (if using a custom domain with services like GitHub Pages): A file containing just your custom domain name.
*   `llms.txt` (optional, emerging): If you want to serve your site as context for LLMs.

## Bonus: Kickstart with an LLM

Feeling lazy or just want a quick starting point? Modern LLMs are surprisingly good at bootstrapping simple scripts. Try a prompt like this (tailor it to your preferences):

```text
Create a simple static site generator in Python. It should:

1. Read all `.md` files from a `posts` directory.
2. Parse YAML frontmatter (title, date) from each file.
3. Convert Markdown content to HTML.
4. Use Jinja2 templates from a `templates` directory: `base.html` and `post.html`.
5. `base.html` should define blocks for `title` and `content`. It should link to a `style.css` file.
6. `post.html` should extend `base.html` and display the post title and content.
7. Generate an `index.html` in a `dist` directory, listing titles and links to all posts, sorted by date (newest first).
8. Generate individual HTML files for each post in the `dist` directory (e.g., `dist/my-post-slug.html`).
9. Copy an `assets` directory (which should contain the `style.css`) to `dist/assets`.
10. The `style.css` should implement a clean, minimalist, responsive design with a dark theme. Use a sans-serif font for readability.

Provide the Python script, example minimal `base.html` and `post.html` templates, and a basic `style.css`.
```

>**Pro tip:** This works even better with AI IDEs like Cursor, Windsurf, or Cline rather than standalone LLMs. These tools can actually create the entire file structure for you automatically – the Python script, template files, CSS, even a sample blog post to test with. No copy-pasting required.

It may not give you a production-ready SSG, but it's a fantastic V0.0.1. You can then iterate, refactor, and add features as you see fit, truly making it your own.

*P.S. I used Cursor with Claude 4 Sonnet for the initial version, and it handled this prompt beautifully – complete with working templates and surprisingly decent CSS.*

## The Payoff? Control and Understanding.

Building your own SSG isn't just a technical exercise. It gives you complete control over your site, zero opaque dependencies, and a deeper understanding of how web content is structured and served. When something breaks, you know exactly where to look (or ask the LLM to do so). When you want a new feature, you're not fighting a framework; you're just adding a bit more code to *your* script.

So, before you reach for that heavy-duty SSG framework, ask yourself: could I just vibe-code this? You might be surprised how far a little bit of scripting can take you.
___
---
title: My bookmarks are public now
subtitle: Rethinking bookmarks for the next decade
tags: [vibe-code, ssg, python, bookmark]
created_at: 2025-06-01
---

So, [Pocket's shutting down](https://getpocket.com/farewell). Cue the minor existential crisis for a 10-year power user like myself. Over a thousand articles saved – a digital trail of my internet rabbit holes and "aha!" moments. The announcement hit, and it wasn't just about losing a service; it was about realizing how much of that curated knowledge was locked away, just for me. And the big question: migrate to another silo, or... something else?

I chose "something else."

The thought of another decade of private bookmarking, another walled garden of links, just didn't sit right. Why store up all this good stuff? Why not make it a public, evolving resource? And even better, why not let others chip in?

That's the new plan: **Public, collaborative, and interactive bookmarks.**

Here are the details on how I'm pulling this off:

**Public**

First, liberation. I grabbed my Pocket data (shoutout to them for a clean CSV export). Then came the data-janitor phase (it took me several hours to finish it): I did some cleaning, replaced old links with updated ones, pruned the dead links, and removed articles that were well past their sell-by date. This newly-curated treasure trove of links is now living on a plain HTML [bookmarks.html](https://eug.github.io/bookmarks.html) page on my site. Simple and effective.

**Collaborative**

Now, for the collaborative bit – this is where it gets fun (and very GitHub-y). I've added an "Add Bookmark" button. Clicking it doesn't pop up a sleek modal or hit a fancy API. Nope. It throws you straight into the GitHub editor for that [templates/bookmarks.html](https://github.com/eug/eug.github.io/edit/main/templates/bookmarks.html#L14) file.

The idea is beautifully simple:

1.  I/You find a cool link.
2.  I/You click "Add Bookmark."
3.  I/You paste the URL and title into the HTML (minimal formatting needed, I'll tidy it up).
4.  I/You submit a Pull Request.
5.  I review, merge, and boom – my/your contribution is live for everyone.

Is it as slick as Pocket's one-click save? Nah. The beauty is in its transparency and the "good enough" approach. I can quickly paste a link myself without fuss, knowing I'll circle back to format it properly later during a review.

**Interactive**

But just *having* them public is one thing. How about making them truly *interactive*? That's where things get even cooler. I've started playing around with feeding this whole heap of bookmarks into Google's NotebookLM. What's the upshot? Well, it means anyone can now 'chat' with my bookmarks – ask questions, dig for specific topics, or even spot broader themes, all without manually combing through hundreds of links.  You can jump in and query my bookmark collection directly here: [Google NotebookLM](https://notebooklm.google.com/notebook/65911a6f-ce1b-4604-bb7d-178aa88f67ea?original_referer=https%3A%2F%2Fwww.google.com%23&pli=1).

---

This isn't just about replacing a tool; it's an experiment in open knowledge sharing. Will anyone else contribute or interact? Maybe, maybe not. But the door's open. And either way, my digital breadcrumbs are now out in the open, hopefully leading others to some of the awesome corners of the web I've stumbled upon.

Let's see what the next decade of *open* bookmarking brings.
